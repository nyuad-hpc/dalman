Dalma System Configuration
====

## SYNOPSIS  

You want to know the system configuration of Dalma, in order to make the most out of it.

## NOTICE
Bigmem, GPU and Visualization nodes will be updated.

## DESCRIPTION  

The most important specification are, the number of cpus per normal compute node: 28, and memory per node: 128GB. Detailed configuration for normal compute nodes:

* 236 compute nodes
* Two Intel Xeon E5-2680 v4 Broadwell CPUs per node
* 2 x 14 cores, 2.4 GHz
* No Hyperthreading
* AVX 2.0 ISA extension
* 128 GB Memory Per Node
* 6,608 CPU cores
* Mellanox EDR InfiniBand
* CentOS 7 Linux distribution
* Slurm batch system
* Support for OpenMP programming model for intra-node parallelization
* OpenMPI (Message Passing Interface) Implementation
* BeeGFS Parallel Filesystem for regular files
* Lustre Parallel Filesystem for large files

We provide Fat, GPU nodes for extra computing requirements. Contact us to tailor your job script.

## EXPLANATION
A long list. So what does it mean?

* Job script should be written in SLURM.
* For parallel jobs, utilize the whole node (28 cores) to maximize the performance. E.g., set `OMP_NUM_THREADS` for hybrid or OpenMP jobs, or set the number of MPI ranks equals the number of nodes times 28 for pure MPI jobs.
* Use maximum 100GB of memory per node. If you need more, use fat node. Why not 128GB? We need to reserve memory for system itself and etc.
* For pre-compiled binaries, try `Centos` or `RHEL` version.
* Before generating tons of data, evaluate your storage requirements and select the most suitable file system.

## AUTHORS 
    NYUAD HPC Apps Team:
    --------------------
        - Benoit Marchand
        - Guowei He
        - Jorge Naranjo

## SEE ALSO

Please refer to the online documentation available [here](https://nyuad-hpc.github.io/dalman/html/dalma.html)


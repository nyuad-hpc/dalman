Running a Multithreading Job on Dalma
====

## SYNOPSIS  

You want to run a job with multi-threading (OpenMP, Pthreads and etc) application, but without multi-processing (e.g., MPI).

## DESCRIPTION  

To accomplish this, follow the steps:

1.- Specify the resouces required in Slurm directives in job script. Most importantly, `--cpus-per-task` for cpus per tasks. This should equal to the number of OpenMP threads (`OMP_NUM_THREADS`) to fully ultilized the allocated resources.

2.- Submit the job.

## EXAMPLE

`Job script for an OpenMP job with 28 threads, fully ultilizing 1 compute node.`
`Save it using a meaningful filename. E.g., "openmp_job.sh"`


```
#!/bin/bash 
## Set number of nodes to run
#SBATCH --nodes=1
# Set number of tasks to run
#SBATCH --ntasks=1
# Set number of cores per task (default is 1)
#SBATCH --cpus-per-task=28
# You may want to be exclusive on the compute node. 
# Remove the extra # below if needed
##SBATCH --exclusive
# Output and error files
#SBATCH -o job.%J.out
#SBATCH -e job.%J.err

# **** Actual commands start here ****
# Set number of OMP threads, directly from SLURM,
#   ultilizting all the cpus allocated.
export OMP_NUM_THREADS=${SLURM_CPUS_PER_TASK}

# Load modules here (safety measure)
module purge

# You may need to load gcc here .. This is application specific
# module load gcc 

# Replace it with your actual command.
./omp-hello
    
```

`Submit the job`

```
sbatch openmp_job.sh
```


## AUTHORS 
    NYUAD HPC Apps Team:
    --------------------
        - Benoit Marchand
        - Guowei He
        - Jorge Naranjo

## SEE ALSO
Please refer to the online documentation available [here](https://nyuad-hpc.github.io/dalman/html/dalma.html)



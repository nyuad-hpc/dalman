.\" generated with Ronn/v0.7.3
.\" http://github.com/rtomayko/ronn/tree/0.7.3
.
.TH "DALMA\-RUN_JOB_THREADS" "" "July 2016" "NYUAD" "Dalma Manual"
.
.SH "SYNOPSIS"
You want to run a job with multi\-threading (OpenMP, Pthreads and etc) application, but without multi\-processing (e\.g\., MPI)\.
.
.SH "DESCRIPTION"
To accomplish this, follow the steps:
.
.P
1\.\- Specify the resouces required in Slurm directives in job script\. Most importantly, \fB\-\-cpus\-per\-task\fR for cpus per tasks\. This should equal to the number of OpenMP threads (\fBOMP_NUM_THREADS\fR) to fully ultilized the allocated resources\.
.
.P
2\.\- Submit the job\.
.
.SH "EXAMPLE"
\fBJob script for an OpenMP job with 28 threads, fully ultilizing 1 compute node\.\fR \fBSave it using a meaningful filename\. E\.g\., "openmp_job\.sh"\fR
.
.IP "" 4
.
.nf

#!/bin/bash
## Set number of nodes to run
#SBATCH \-\-nodes=1
# Set number of tasks to run
#SBATCH \-\-ntasks=1
# Set number of cores per task (default is 1)
#SBATCH \-\-cpus\-per\-task=28
# Walltime format hh:mm:ss
#SBATCH \-\-time=00:30:00
# You may want to be exclusive on the compute node\.
# Remove the extra # below if needed
##SBATCH \-\-exclusive
# Output and error files
#SBATCH \-o job\.%J\.out
#SBATCH \-e job\.%J\.err

# **** Actual commands start here ****
# Set number of OMP threads, directly from SLURM,
#   ultilizting all the cpus allocated\.
export OMP_NUM_THREADS=${SLURM_CPUS_PER_TASK}

# Load modules here (safety measure)
module purge

# You may need to load gcc here \.\. This is application specific
# module load gcc

# Replace it with your actual command\.
omp\-hello
.
.fi
.
.IP "" 0
.
.P
\fBSubmit the job\fR
.
.IP "" 4
.
.nf

sbatch openmp_job\.sh
.
.fi
.
.IP "" 0
.
.SH "AUTHORS"
.
.nf

NYUAD HPC Apps Team:
\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-\-
    \- Benoit Marchand
    \- Guowei He
    \- Jorge Naranjo
.
.fi
.
.SH "SEE ALSO"
Please refer to the online documentation available here \fIhttps://nyuad\-hpc\.github\.io/dalman/html/dalma\.html\fR
